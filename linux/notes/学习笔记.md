IP：192.168.100.x
MAC：255.255.255.0
默认网关：2

Linux命令

`cat` 查看文件内容
`cat /etc` 其中斜杠表示根目录，可以输入一部分，按tab键补全

```
onboot=no -> yes
boootproto=dhcp -> static
IPADDR=192.168.100.30
GATEWAY=192.168.100.2
DNS1=8.8.8.8
```

`vi` 编辑文件
`vi /etc/sysconfig/network` 配置主机名
a或i 进入编辑模式
esc  退出编辑模式
:wq 保存并退出
:quit 直接退出


`service network restart` 重启网卡配置
`ping ...` 

SecureCRT.exe
修改主机名
`cat /etc/sysconfig/network`
`vi /etc/sysconfig/network`

修改主机名与ip地址的映射

`cat /etc/hosts`

使环境变量生效：`source /etc/profile`

关闭防火墙
`service iptables stop` //临时关闭防火墙
`chk config iptables off && setenforce 0` 永久关闭

安装lrzsz（上传下载服务插件），虚拟机可以连上外网
`yum install -y lrzsz` 不交互

安装时间同步器
`yum -y install ntpdate`
`ntpdate -u ntp.api.bz`
`date "+%Y-%m-%d %H:%M:%S"`

添加一个自定义用户
`add user 姓名的拼音`
`passwd 姓名的拼音 123456`

> 注意：不要选中`安装后自动启动虚拟机`

```
192.168.46.134 hadoop01
192.168.46.135 hadoop02
192.168.46.136 hadoop03
```

vi /etc/profile

```
export JAVA_HOME=/home/shicheng/export/servers/jdk
export HADOOP_HOME=/home/shicheng/export/servers/hadoop
export PATH=$PATH:$HOME/bin:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
```

***

hdfs 分布式存储

MapReduce （继承Mapper和Reduce） 数据计算（数据处理）

太麻烦，效率不是很高，现在已经不是主流

yarn 集群资源统一管理

配置hadoop
cd ~server/hadoop/etc/hadoop

* mapred-env.sh

```
export JAVA_HOME=/home/shicheng/servers/jdk
```

* hadoop-env.sh

```
export JAVA_HOME=/home/shicheng/servers/jdk
```

* yarn-env.sh

```
export JAVA_HOME=/home/shicheng/servers/jdk 
```

* core-site.xml

```
<configuration>
<!-- HDFS的默认路径，端口9000 -->
<property>
<name>fs.defaultFS</name>
<value>hdfs://master:9000</value>
</property>
<!-- hadoop运行时，存放数据的临时文件的路径 -->
<property>
<name>hadoop.tmp.dir</name>
<value>/home/shicheng/export/servers/hadoop/tmp</value>
</property>
</configuration>
```

* hdfs-site.xml：

```
<configuration>
<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
<name>dfs.permissions</name>
<value>false</value>
</property>
</configuration>
```

* yarn-site.xml

```
<?xml version="1.0"?>
<configuration>
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
<property>
<name>yarn.resourcemanager.address</name>
<value>master:18040</value>
</property>
<property>
<name>yarn.resourcemanager.scheduler.address</name>
<value>master:18030</value>
</property>
<property>
<name>yarn.resourcemanager.resource-tracker.address</name>
<value>master:18025</value>
</property>
<property>
<name>yarn.resourcemanager.admin.address</name>
<value>master:18141</value>
</property>
<property>
<name>yarn.resourcemanager.webapp.address</name>
<value>master:18088</value>
</property> 
</configuration>
```

* mapred-site.xml

```
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>
</configuration>
```

* 修改slaves

```
hadoop01
hadoop02
hadoop03
```

* 将当前master节点上的jdk、hadoop以及 .bash_profile分发到slave1、slave2上（在hadoop01的~目录下）


scp -r export/ hadoop02:~
scp -r export/ hadoop03:~
scp ~/.bash_profile hadoop02:~/
scp ~/.bash_profile hadoop03:~/

所有节点执行source ~/.bash_profile

* 后续

hadoop namenode -format
start-all.sh

jpa

主节点：
1796 NameNode
2374 Jps
1978 SecondaryNameNode
2123 ResourceManager

从节点：
1593 DataNode
1787 Jps
1692 NodeManager

`hadoop fs` 查看分布式集群中有哪些数据

hdfs

hadoop fs -ls /
hadoop fs -mrdir /words
hadoop fs -rm /words
hadoop fs -cat /words/xx
hadoop fs -put ./aa /words  将本地文件存储到分布式环境中
hadoop fs -get /words/aa  将分布式环境中的文件下载到本地

MapReduce

map shuffle reduce

hadoop.dll
winutils.exe

bin目录
windows/system32目录

common
hdfs
mapreduce
yarn
将其中所有的jar包复制到项目的lib文件夹